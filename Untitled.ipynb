{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0825af28-f162-42b3-ab8c-1aeaf1c53f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce1e976-e142-470c-9c79-5d64569a8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pandas.read_table(r\"./CCL_2023_assessment_data/data/demographics.txt\")\n",
    "projections = pandas.read_table(r\"./CCL_2023_assessment_data/data/projections.txt\")\n",
    "results = pandas.read_table(r\"./CCL_2023_assessment_data/data/results.txt\")\n",
    "geoid_key = pandas.read_table(r\"./CCL_2023_assessment_data/data/geoid_key.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3624c4b8-60d8-4696-8b2b-bc4c63c98904",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb1 = pd.merge(demographics, projections, on='geoid', how='left')\n",
    "comb2 = pd.merge(comb1, results, on = 'geoid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "343f9d4e-3f85-4d7d-a097-353c98ddd573",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb2['mw_off'] = (comb2['mw_yes'] / (comb2['mw_yes'] + comb2['mw_no'])) - (comb2['proj_mw_yes'] / comb2['proj_votes'])\n",
    "comb2['bg_off'] = (comb2['bg_yes'] / (comb2['bg_yes'] + comb2['bg_no'])) - (comb2['proj_bg_yes'] / comb2['proj_votes'])\n",
    "comb2['rcv_off'] = (comb2['rcv_yes'] / (comb2['rcv_yes'] + comb2['rcv_no'])) - (comb2['proj_rcv_yes'] / comb2['proj_votes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb8b46b3-b684-4193-89c3-ba891464fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "demos_off = comb2.drop(['proj_rcv_yes', 'proj_bg_yes', 'proj_mw_yes', 'rcv_yes', 'bg_yes', 'mw_yes', 'rcv_no', 'bg_no', 'mw_no'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "36b925e6-ef03-4a64-aa29-96f77a898e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13) #arbitrary seed\n",
    "\n",
    "def split_train_test(data, test_ratio): #defining function/inputs\n",
    "    shuffled_indices = np.random.permutation(len(data)) #shuffling the data to prevent learning any patterns from the data's original order\n",
    "    test_set_size = int(len(data) * test_ratio) #defining the size of our test set given the user defined ratio (i will use 20% for my test set size)\n",
    "    test_indices = shuffled_indices[:test_set_size] #slicing out our test list starting from 0 and ending at the size of the test list\n",
    "    train_indices = shuffled_indices[test_set_size:] #slicing out our training list starting from index of test_list_size (where the last line ended, becuase it ends at this value -1) and going ot the end of the data\n",
    "                                                    #the colons here are like when you do 1:10\n",
    "                                                    #for the first line it's startofdata:test_list_size\n",
    "                                                    #for the second it's test_list_size:endofdata\n",
    "    return data.iloc[train_indices], data.iloc[test_indices] #making two new dataframes based on the train/test indices\n",
    "\n",
    "train_set, test_set = split_train_test(demos_off, .2)\n",
    "#We have a few missing values for our offs for counties where results aren't present\n",
    "#I'm choosing to drop these rather than replace w/ medians like I do for hhincome, b/c the result is so crucial to our analysis\n",
    "train_set = train_set.dropna(subset=['mw_off', 'bg_off', 'rcv_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "305cc444-db03-4091-80f3-1439567ffef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_registered           0.000000\n",
       "share_dem              0.000000\n",
       "share_rep              0.000000\n",
       "share_white            0.000000\n",
       "share_afam             0.000000\n",
       "share_female           0.000000\n",
       "avg_hhincome           0.002545\n",
       "avg_popdens            0.000000\n",
       "avg_partyscore         0.000000\n",
       "avg_collegescore       0.000000\n",
       "avg_gunownscore        0.000000\n",
       "avg_gvpscore           0.000000\n",
       "avg_churchscore        0.000000\n",
       "avg_marijuanascore     0.000000\n",
       "avg_fiscalprogscore    0.000000\n",
       "avg_choicescore        0.000000\n",
       "avg_enviroscore        0.000000\n",
       "proj_votes             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping geoid as well since we set our own indices - don't want geoid as a predictor\n",
    "train_set_no_targets = train_set.drop(['mw_off', 'bg_off', 'rcv_off', 'geoid'], axis = 1)\n",
    "train_set_mw_labels = train_set['mw_off'].copy()\n",
    "train_set_bg_labels = train_set['bg_off'].copy()\n",
    "train_set_rcv_labels = train_set['rcv_off'].copy()\n",
    "\n",
    "train_copy = train_set_no_targets.copy()\n",
    "train_copy.isnull().sum() / len(train_copy)\n",
    "#Looks like we have a few missing values for avg_hhincome, so I'm going to impute those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "594d789d-c718-4a15-b56a-8f17365b9184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.60000e+02 2.71000e-01 3.03000e-01 9.33000e-01 3.00000e-03 5.02000e-01\n",
      " 4.11585e+01 1.60893e+02 4.64950e+01 4.13340e+01 6.25320e+01 3.18270e+01\n",
      " 2.34560e+01 6.28930e+01 3.10760e+01 5.35940e+01 2.66730e+01 7.12000e+02]\n",
      "[9.60000e+02 2.71000e-01 3.03000e-01 9.33000e-01 3.00000e-03 5.02000e-01\n",
      " 4.11585e+01 1.60893e+02 4.64950e+01 4.13340e+01 6.25320e+01 3.18270e+01\n",
      " 2.34560e+01 6.28930e+01 3.10760e+01 5.35940e+01 2.66730e+01 7.12000e+02]\n",
      "If this prints as zeroes, we replaced the missing values:\n",
      "n_registered           0.0\n",
      "share_dem              0.0\n",
      "share_rep              0.0\n",
      "share_white            0.0\n",
      "share_afam             0.0\n",
      "share_female           0.0\n",
      "avg_hhincome           0.0\n",
      "avg_popdens            0.0\n",
      "avg_partyscore         0.0\n",
      "avg_collegescore       0.0\n",
      "avg_gunownscore        0.0\n",
      "avg_gvpscore           0.0\n",
      "avg_churchscore        0.0\n",
      "avg_marijuanascore     0.0\n",
      "avg_fiscalprogscore    0.0\n",
      "avg_choicescore        0.0\n",
      "avg_enviroscore        0.0\n",
      "proj_votes             0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "imputer_median = SimpleImputer(strategy=\"median\")\n",
    "#I would narrow to just int/float here, but that's all we have so we're good\n",
    "#This data is super clean, but there's a few NaNs for household income, so I'm imputing w/ the median for those\n",
    "#I'm replacing w/ median rather than dropping b/c this dataset isn't huge - I don't want to lose rows\n",
    "imputer_median.fit(train_copy)\n",
    "print(imputer_median.statistics_)\n",
    "print(train_copy.median().values)\n",
    "X = imputer_median.transform(train_copy)\n",
    "train_final = pd.DataFrame(X, columns=train_copy.columns,\n",
    "                          index=train_copy.index)\n",
    "\n",
    "#Checking if our cleaning worked\n",
    "ifmissing = train_final.isnull().values.any()\n",
    "prctmissing = train_final.isnull().sum() / len(train_final)\n",
    "prctmissing\n",
    "print(\"If this prints as zeroes, we replaced the missing values:\\n{}\".format(prctmissing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "447752dd-1c7f-407c-a023-89775b82cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are a few missing values here b/c of counties where there aren't results.\n",
    "#I am choosing to drop those rows rather than impute, b/c I fear filling in median error for counties is too big a leap.\n",
    "train_set_mw_labels_clean = train_set_mw_labels.dropna()\n",
    "train_set_bg_labels_clean = train_set_bg_labels.dropna()\n",
    "train_set_rcv_labels_clean = train_set_rcv_labels.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a3fe76aa-540c-469b-be16-c4073f70994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train_final, train_set_mw_labels_clean)\n",
    "lin_predict = lin_reg.predict(train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0b679631-fe67-4a67-b1f7-508ba8fcfb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004257395329098849 0.06524871898435132 0.045070951801944766 0.3172051523617958\n"
     ]
    }
   ],
   "source": [
    "#Evaluating linear regression predictions\n",
    "lin_model_mse = mean_squared_error(train_set_mw_labels, lin_predict, squared=True)\n",
    "lin_model_rmse = mean_squared_error(train_set_mw_labels, lin_predict, squared=False)\n",
    "lin_model_mae = mean_absolute_error(train_set_mw_labels, lin_predict)\n",
    "lin_model_r2 = r2_score(train_set_mw_labels, lin_predict)\n",
    "print(lin_model_mse, lin_model_rmse, lin_model_mae, lin_model_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4b19250c-cb4e-4afc-9b02-7ac7aba42b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_registered</td>\n",
       "      <td>-0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>share_dem</td>\n",
       "      <td>0.328905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>share_rep</td>\n",
       "      <td>-0.410329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>share_white</td>\n",
       "      <td>0.022755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>share_afam</td>\n",
       "      <td>0.876112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>share_female</td>\n",
       "      <td>-0.234267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avg_hhincome</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>avg_popdens</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>avg_partyscore</td>\n",
       "      <td>-0.009931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>avg_collegescore</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>avg_gunownscore</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>avg_gvpscore</td>\n",
       "      <td>0.004225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>avg_churchscore</td>\n",
       "      <td>0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>avg_marijuanascore</td>\n",
       "      <td>-0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>avg_fiscalprogscore</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>avg_choicescore</td>\n",
       "      <td>-0.002095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>avg_enviroscore</td>\n",
       "      <td>0.006923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>proj_votes</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         1\n",
       "0          n_registered -0.000013\n",
       "1             share_dem  0.328905\n",
       "2             share_rep -0.410329\n",
       "3           share_white  0.022755\n",
       "4            share_afam  0.876112\n",
       "5          share_female -0.234267\n",
       "6          avg_hhincome  0.000143\n",
       "7           avg_popdens  0.000010\n",
       "8        avg_partyscore -0.009931\n",
       "9      avg_collegescore  0.000304\n",
       "10      avg_gunownscore  0.000069\n",
       "11         avg_gvpscore  0.004225\n",
       "12      avg_churchscore  0.000598\n",
       "13   avg_marijuanascore -0.000431\n",
       "14  avg_fiscalprogscore  0.000277\n",
       "15      avg_choicescore -0.002095\n",
       "16      avg_enviroscore  0.006923\n",
       "17           proj_votes  0.000016"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(train_final.columns, lin_reg.coef_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4bcac8e8-3cde-4604-b0c1-35acbea332a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Tried trying going over degree=2 for this, but it requires ~2x the RAM I have on my system. I commented out those lines.\n",
    "#Tried grid search as well, but was having errors. Entirely possible that was also a RAM issue.\n",
    "\n",
    "#Adding the square of each feature in the training set as a new feature\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "#poly_features3 = PolynomialFeatures(degree=3)\n",
    "\n",
    "#Making the regression\n",
    "poly_model = LinearRegression()\n",
    "#poly_model3 = LinearRegression()\n",
    "\n",
    "#Fitting\n",
    "train_cleaned_poly = poly_features.fit_transform(train_final)\n",
    "poly_model.fit(train_cleaned_poly, train_set_mw_labels)\n",
    "\n",
    "#Making the predictions\n",
    "poly_predict = poly_model.predict(train_cleaned_poly)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1cd737fb-31fe-4887-900b-b7952e230ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002236687487591149 0.04729363051819081 0.03439876998675301 0.6412833260125423\n"
     ]
    }
   ],
   "source": [
    "#Evaluating polynimaial\n",
    "poly_model_mse = mean_squared_error(train_set_mw_labels, poly_predict, squared=True)\n",
    "poly_model_rmse = mean_squared_error(train_set_mw_labels, poly_predict, squared=False)\n",
    "poly_model_mae = mean_absolute_error(train_set_mw_labels, poly_predict)\n",
    "poly_model_r2 = r2_score(train_set_mw_labels, poly_predict)\n",
    "print(poly_model_mse, poly_model_rmse, poly_model_mae, poly_model_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
